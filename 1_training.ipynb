{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "import torch\n",
    "import tqdm\n",
    "\n",
    "from source.dataset import JetEvents, JetClass, JetNet, JetLightningDataModule\n",
    "from source.litmodel import TorchLightningModule\n",
    "from source.models.part import ParticleTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `yaml` configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yaml', 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "rnd_seed = config['rnd_seed']\n",
    "L.seed_everything(rnd_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class of the target dataset.\n",
    "dataset_str_name: str = config['dataset']\n",
    "DATASET: JetEvents = globals()[dataset_str_name]\n",
    "\n",
    "# Load the dataset.\n",
    "channels = tqdm.tqdm(DATASET.CHANNELS, desc='Loading dataset')\n",
    "jet_events_list = [DATASET(channel, **config[DATASET.__name__]) for channel in channels]\n",
    "\n",
    "# Create the data module.\n",
    "print('Creating data module.')\n",
    "data_module = JetLightningDataModule(\n",
    "    jet_events_list=jet_events_list,\n",
    "    pad_num_ptcs=config[DATASET.__name__]['pad_num_ptcs'],\n",
    "    **config['DataModule'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams_part = {\n",
    "    'ParEmbed': {\n",
    "        'input_dim': DATASET.INPUT_DIM,\n",
    "        'embed_dim': [128, 512, 128],\n",
    "    },\n",
    "    'IntEmbed': {\n",
    "        'input_dim': 4 if DATASET.INCLUDE_MASS else 3,\n",
    "        'embed_dim': [64, 64, 64],\n",
    "    },\n",
    "    'ParAtteBlock': {\n",
    "        'num_heads': 8,\n",
    "        'fc_dim': 512,\n",
    "        'dropout': 0.1,\n",
    "    },\n",
    "    'ClassAtteBlock': {\n",
    "        'num_heads': 8,\n",
    "        'fc_dim': 512,\n",
    "        'dropout': 0.0,\n",
    "    },\n",
    "    'num_ParAtteBlock': 8,\n",
    "    'num_ClassAtteBlock': 2,\n",
    "}\n",
    "\n",
    "model = ParticleTransformer(score_dim=len(channels), parameters=hparams_part)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lightning DataModule and Model\n",
    "accelerator = 'gpu' if torch.cuda.is_available() else 'cpu'\n",
    "optimizer = torch.optim.RAdam(model.parameters(), lr=config['lr'])\n",
    "lit_model = TorchLightningModule(model, optimizer=optimizer, score_dim=len(channels), print_log=False)\n",
    "\n",
    "# Lightning Logger\n",
    "save_dir = os.path.join('training_logs', DATASET.__name__)\n",
    "logger = CSVLogger(save_dir=save_dir, name=f\"{model.__class__.__name__}_{rnd_seed}\", version='lastest_run')\n",
    "\n",
    "# Lightning Trainer\n",
    "trainer = L.Trainer(\n",
    "    accelerator=accelerator,\n",
    "    max_epochs=config['num_epochs'],\n",
    "    logger=logger,\n",
    "    num_sanity_val_steps=0,\n",
    "    callbacks=[ModelCheckpoint(\n",
    "        monitor='valid_auc',\n",
    "        mode='max',\n",
    "        every_n_epochs=1,\n",
    "        save_last=True,\n",
    "        save_top_k=-1,\n",
    "        filename='{epoch}',\n",
    "    )],\n",
    ")\n",
    "\n",
    "# Save the model for quick loading.\n",
    "os.makedirs(logger.log_dir, exist_ok=True)\n",
    "torch.save(model, f\"{logger.log_dir}/model.pt\")\n",
    "\n",
    "trainer.fit(lit_model, data_module)\n",
    "trainer.test(lit_model, data_module)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
