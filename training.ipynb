{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "import torch\n",
    "import tqdm\n",
    "\n",
    "from source.data import jetclass, jetnet, topqcd\n",
    "from source.data.datamodule import JetLightningDataModule\n",
    "from source.models.litmodel import TorchLightningModule\n",
    "from source.models.part import ParticleTransformer, AttentionBlock\n",
    "from source.models.pnet import ParticleNet\n",
    "\n",
    "L.seed_everything(42)\n",
    "\n",
    "dataset = jetclass\n",
    "model_class = ParticleTransformer\n",
    "train_model = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data setup and `data_module`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lightning_data_module(dataset, num_train, num_valid, num_test, batch_size) -> JetLightningDataModule:\n",
    "    \"\"\"Create a Lightning DataModule for the given dataset.\"\"\"\n",
    "\n",
    "    # Jet Class Dataset\n",
    "    if dataset == 'jetclass':\n",
    "        tqdm_channels = tqdm.tqdm(jetclass.channels, desc='Loading JetClass Dataset')\n",
    "        jet_events_list = [jetclass.JetEvents(channel, num_root=1) for channel in tqdm_channels]\n",
    "    \n",
    "    # Jet Net Dataset\n",
    "    elif dataset == 'jetnet':\n",
    "        tqdm_channels = tqdm.tqdm(jetnet.channels, desc='Loading JetNet Dataset')\n",
    "        jet_events_list = [jetnet.JetEvents(channel) for channel in tqdm_channels]\n",
    "    \n",
    "    # Top QCD Dataset\n",
    "    elif dataset == 'topqcd':\n",
    "        tqdm_channels = tqdm.tqdm(topqcd.channels, desc='Loading TopQCD Dataset')\n",
    "        jet_events_list = [\n",
    "            (\n",
    "                topqcd.JetEvents(channel, mode='train', num_data=num_train) + \n",
    "                topqcd.JetEvents(channel, mode='valid', num_data=num_valid) + \n",
    "                topqcd.JetEvents(channel, mode='test', num_data=num_test)\n",
    "            ) for channel in tqdm_channels\n",
    "        ]\n",
    "    \n",
    "    return JetLightningDataModule(jet_events_list, num_train, num_valid, num_test, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading JetClass Dataset: 100%|██████████| 10/10 [00:14<00:00,  1.42s/it]\n",
      "Creating JetLightningDataModule: 100%|██████████| 10/10 [00:28<00:00,  2.88s/it]\n"
     ]
    }
   ],
   "source": [
    "# Dimension of the model output (equivalent to the number of classes)\n",
    "score_dim: int = len(dataset.channels)\n",
    "\n",
    "# The dataset is a python module stored at `source.data.dataset_name`\n",
    "dataset_name: str = dataset.__name__.split('.')[-1]\n",
    "\n",
    "# Dictionary of the data configuration\n",
    "data_module_config = {\n",
    "    'dataset': dataset_name,\n",
    "    'num_train': 1000,\n",
    "    'num_valid': 100,\n",
    "    'num_test': 100,\n",
    "    'batch_size': 32,\n",
    "}\n",
    "\n",
    "# Create the Lightning DataModule\n",
    "data_module: JetLightningDataModule = lightning_data_module(**data_module_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training (trained with `LightningModule`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# Model setup (`yaml` configuration file)\n",
    "with open(f\"configs/{model_class.__name__}.yaml\", 'r') as file:\n",
    "    hparams = yaml.safe_load(file)[model_class.__name__]\n",
    "    model = model_class(score_dim=score_dim, parameters=hparams)\n",
    "\n",
    "# Lightning DataModule and Model\n",
    "accelerator = 'gpu' if torch.cuda.is_available() else 'cpu'\n",
    "optimizer = torch.optim.RAdam(model.parameters(), lr=1E-3)\n",
    "lightning_model = TorchLightningModule(model, optimizer=optimizer, score_dim=score_dim, print_log=False)\n",
    "\n",
    "# Lightning Logger\n",
    "save_dir = os.path.join('training_logs', dataset_name)\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "logger = CSVLogger(save_dir=save_dir, name=f\"{model_class.__name__}\", version='lastest_run')\n",
    "\n",
    "# Lightning Trainer\n",
    "trainer = L.Trainer(\n",
    "    accelerator=accelerator,\n",
    "    max_epochs=10,\n",
    "    logger=logger,\n",
    "    num_sanity_val_steps=0,\n",
    "    callbacks=[ModelCheckpoint(\n",
    "        monitor='valid_auc',\n",
    "        mode='max',\n",
    "        every_n_epochs=1,\n",
    "        save_last=True,\n",
    "        save_top_k=-1,\n",
    "        filename='{epoch}',\n",
    "    )],\n",
    ")\n",
    "\n",
    "if train_model:\n",
    "    trainer.fit(lightning_model, data_module)\n",
    "    trainer.test(lightning_model, data_module)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
